<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>YUAN, Li (袁粒)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=-5juAR0AAAAJ&hl=en">Google Scholar</a></div>
<div class="menu-item"><a href="https://github.com/yuanli2333">GitHub</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>YUAN, Li (袁粒) </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://yuanli2333.github.io/"><img src="photos/bio.jpg" alt="alt text" width="131px" height="160px" /></a>&nbsp;</td>
<td align="left"><p>Tenure-track Assistant Professor<br />
Peking University, <br />
School of Electrical and Computer Engineering (ECE), <br />
Shenzhen Graduate School, <br />
E-mail: <a href="yuanli@u.nus.edu">yuanli@u.nus.edu</a></p>
</td></tr></table>

<h2>Education</h2>
<ul>
<li><p>Ph.D. <a href="https://www.nus.edu.sg/ ">National University of Singapore, NUS</a>, 2017.08-2021.10</p>
</li>
<li><p>B.E., <a href=" https://en.ustc.edu.cn/"> University of Science and Technology of China (USTC) </a>, 2013.09-2017.06</p>

</p> In NUS, I did research in LV lab, fortunately advised by <a href="https://sites.google.com/site/jshfeng/home"> Prof. Jiashi Feng</a>, Prof. Francis EH Tay and <a href=" https://yanshuicheng.ai/ "> Prof. Shuicheng Yan</a>, and I also spend more than half year in Harvard University, fortunately advised by <a href=" https://livingstone.hms.harvard.edu/people"> Prof. Margaret Livingstone. </a> </p>
</ul>

<h2>Work Experience</h2>
<ul>
<li><p>Tencent AI Lab,  PhD research intern, work with Dr.Wei Liu and Dr.Zequn Jie, 2018.12-2019.03
</li>
<li><p>YITU Singapore, PhD research intern, work with Dr.Yunpeng Chen and Prof.Shuicheng Yan, 2020.06-2021.01
</li>
<li><p> Tencent, Visiting Research, work with Dr.Wei Liu and Dr.Zhifeng Li, 2021.11-2022.01
</li>
</ul>


<h2>Research</h2>
<p>My research interests include: </p>
<ul>
<li><p>Computer Vision</p>
</li>
<li><p>Deep Learning</p>
</li>
<li><p> Brain Science and Cognitive Neuroscience</p>
</li>
</ul>

<p><a href="https://scholar.google.com/citations?user=-5juAR0AAAAJ&hl=en">Full list of publications in Google Scholar</a>.</p>

<h3>
	<a name='publications'></a> Preprint
</h3>


<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>VOLO: Vision Outlooker for Visual Recognition
      </strong><br />
       <strong>Li Yuan</strong>, Qibin Hou, Zihang Jiang, Jiashi Feng, Shuicheng Yan<br /> 
      VOLO is the first model exceeds 87.0% top-1 accuracy on ImageNet without using extra data <br />
      <a href="https://arxiv.org/abs/2106.13112">[Axriv]</a>
	    <a href="https://github.com/sail-sg/volo">[Code]</a> <br />
    </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Adversarial Images for the Primate Brain
      </strong><br />
       <strong>Li Yuan</strong>, Will Xiao, Gabriel Kreiman, Francis E.H. Tay, Jiashi Feng, Margaret S. Livingstone<br /> 
      <a href="https://arxiv.org/abs/2011.05623">[Axriv]</a>
	    <a href="">[Code Coming]</a> <br />
    </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Full Transformer Framework for Robust Point Cloud Registration with Deep Information Interaction
      </strong><br />
      Guangyan Chen, Meiling Wang, Yufeng Yue, Qingxiang Zhang, <strong>Li Yuan</strong><br /> 
      <a href="https://arxiv.org/abs/2112.09385">[Axriv]</a>
	    <a href="https://github.com/CGuangyan-BIT/DIT">[Code]</a> <br />
    </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition     </strong><br />
      Qibin Hou, Zihang Jiang, <strong>Li Yuan</strong>, Ming-Ming Cheng, Shuicheng Yan, Jiashi Feng<br /> 
      <a href="https://arxiv.org/abs/2106.12368">[Axriv]</a>
	    <a href="https://github.com/Andrew-Qibin/VisionPermutator">[Code]</a> <br />
    </p>
  </div>
</div>


<h3>
	<a name='publications'></a> Selected Publications
</h3>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet
      </strong><br />
       <strong>Li Yuan</strong>,  Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zihang Jiang, Francis EH Tay, Jiashi Feng, Shuicheng Yan<br /> 
       International Conference on Computer Vision (<strong>ICCV</strong>), 2021 <br />
	    <a href="https://arxiv.org/abs/2101.11986">[Axriv]</a>
	    <a href="https://github.com/yitu-opensource/T2T-ViT">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>PnP-DETR: Towards Efficient Visual Analysis with Transformers
      </strong><br />
       Tao Wang, <strong>Li Yuan†</strong>, Yunpeng Chen, Jiashi Feng, Shuicheng Yan<br /> 
       International Conference on Computer Vision (<strong>ICCV</strong>), 2021 <br />
	    <a href="https://arxiv.org/abs/2109.07036">[Axriv]</a>
	    <a href="https://github.com/twangnh/pnp-detr">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Continual Learning via Bit-Level Information Preserving
      </strong><br />
       Yujun Shi, <strong>Li Yuan†</strong>, Yunpeng Chen, Jiashi Feng<br /> 
       IEEE Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2021 <br />
	    <a href="https://arxiv.org/abs/2105.04444">[Axriv]</a>
	    <a href="https://github.com/Yujun-Shi/BLIP">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Revisiting Knowledge Distillation via Label Smoothing Regularization</strong><br />
       <strong>Li Yuan</strong>, Francis EH Tay, Guilin Li, Tao Wang, Jiashi Feng<br /> 
       IEEE Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020 (<font color="#FF0000"><strong>Oral</strong></font>) <br />
	    <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Yuan_Revisiting_Knowledge_Distillation_via_Label_Smoothing_Regularization_CVPR_2020_paper.html">[Axriv]</a>
	    <a href="https://github.com/yuanli2333/Teacher-free-Knowledge-Distillation">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Central Similarity Quantization for Efficient Image and Video Retrieval</strong><br />
       <strong>Li Yuan</strong>, Tao Wang, Xiaopeng Zhang, Francis EH Tay, Zequn Jie, Wei Liu, Jiashi Feng<br /> 
       IEEE Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020 <br />
	    <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Yuan_Central_Similarity_Quantization_for_Efficient_Image_and_Video_Retrieval_CVPR_2020_paper.html">[Axriv]</a>
	    <a href="https://github.com/yuanli2333/Hadamard-Matrix-for-hashing">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Toward Accurate Person-level Action Recognition in Videos of Crowded Scenes</strong><br />
       <strong>Li Yuan</strong>, Yichen Zhou, Shuning Chang, Ziyuan Huang, Yupeng Chen, Xuecheng Nie, Tao Wang, Jiashi Feng, Shuicheng Yan<br /> 
       ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2020 <br />
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Cycle-SUM: Cycle-Consistent Adversarial LSTM Networks for Unsupervised Video Summarization      </strong><br />
      <strong>Li Yuan</strong>, Francis Eng Hock Tay, Ping Li,  Li Zhou, Jiashi Feng<br />
       AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2019 <br />
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Unsupervised Video Summarization With Cycle-Consistent Adversarial LSTM Networks</strong><br />
       <strong>Li Yuan</strong>, Francis Eng Hock Tay, Ping Li, Jiashi Feng<br /> 
       IEEE Transactions on Multimedia  (<strong>IEEE TMM</strong>), 2019 <br />
   </p>
  </div>
</div>

<p> </p>
<p><b>Selected Co-publications:</b></p>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization</strong><br />
       Zeke Xie, <strong>Li Yuan</strong>, Zhanxing Zhu, Masashi Sugiyama<br /> 
       International Conference on Machine Learning (<strong>ICML</strong>), 2021 (<font color="#FF0000"><strong>spotlight</strong></font>) <br />
	    <a href="https://arxiv.org/abs/2103.17182">[Axriv]</a>
	    <a href="https://github.com/zeke-xie/Positive-Negative-Momentum">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>All Tokens Matter: Token Labeling for Training Better Vision Transformers</strong><br />
      Zihang Jiang, Qibin Hou, <strong>Li Yuan</strong>,  Daquan Zhou, Yujun Shi, Xiaojie Jin, Anran Wang, Jiashi Feng<br /> 
      Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2021 <br />
	    <a href="https://arxiv.org/abs/2104.10858">[Axriv]</a>
	    <a href="https://github.com/zihangJiang/TokenLabeling">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Distilling Object Detectors With Fine-Grained Feature Imitation</strong><br />
      Tao Wang, <strong>Li Yuan</strong>,  Xiaopeng Zhang, Jiashi Feng<br /> 
      IEEE Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019 <br />
	    <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Distilling_Object_Detectors_With_Fine-Grained_Feature_Imitation_CVPR_2019_paper.html">[Axriv]</a>
	    <a href="https://github.com/twangnh/Distilling-Object-Detectors">[Code]</a>
   </p>
  </div>
</div>

<div class="media">
  <div class="media-body">
    <p class="media-heading">
      <strong>Few-shot adaptive faster r-cnn</strong><br />
      Tao Wang, Xiaopeng Zhang, <strong>Li Yuan</strong>, Jiashi Feng<br /> 
      IEEE Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2019 <br />
   </p>
  </div>
</div>

<h3>Academic service</h3>
<p><b>Guest Editor</b></p>
<ul>
<li><p>MDPI-Sensors (IF: 3.5)</p>
</li>
</ul>

<p><b>Reviewer</b></p>
<ul>
<li><p>IEEE TPAMI, TNNLS, TMM, Neurocomputing, Pattern Recognition etc.</p>
</li>
<li><p>CVPR, ICCV, ECCV, ICML, NeurIPS, ICLR, AAAI etc.</p>
</li>
</ul>

<p><b>Awards</b></p>
<ul>
<li><p>NUS Research Scholarship</p>
</li>
<li><p>ACM MM 2020 Grand Challenge Winner</p>
</li>
<li><p>Winner of Human in Event Challenge, Track4</p>
</li>
</ul>

</td>
</tr>
</table>
</body>
</html>
